{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTrees.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nidhin-koshy/Notebooks/blob/master/DecisionTrees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8b_i9bFdlM7",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree Calssifier\n",
        "\n",
        "A decision tree classifier partitions the feature space in a hierarchical manner and assigns class labels to each partition. The partition rules are along the different feature axes and hence we can provide a descriptive and intuitive classification rule for each partition. The key part of the algorithm is the way in which the partitioning is done.\n",
        "\n",
        "    Decision Tree Algorithm: For a a given set of samples and labels, a split finds the best feature and a partioning that reduces the class entropy (or gini index). This provides us with two sets of samples and labels. The above procedure is repeated on each generated set of samples and labels till the max_depth of the tree is reached."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgNi7Xxnx3-Z",
        "colab_type": "text"
      },
      "source": [
        "### Import required modules/libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-DlZ25qwgZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpS0wNeLsrM6",
        "colab_type": "text"
      },
      "source": [
        "## Define required functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iseWRWMIkeSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a class for a node in the tree\n",
        "class Tree(object):\n",
        "    def __init__(self):\n",
        "        self.split=False # Is this node further split?\n",
        "        self.parent=None # Which is the parent node of the node\n",
        "        self.depth=0 #At what depth is this node\n",
        "        self.is_left=False #Is this a left node of the parent node?\n",
        "        self.left = None #The left child node of this node\n",
        "        self.right = None #The right child node of this node\n",
        "        #self.data = None \n",
        "        self.feature = None #The feature used for the split in this node\n",
        "        self.threshold = None #The threshold used for the split on the above feature\n",
        "        self.entropy_before_split=None #entropy before the split\n",
        "        self.entropy_after_split=None #entropy after the split\n",
        "        self.num_labels=[] #number of instances of different labels\n",
        "        self.total_labels=0 #total number of labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxErr70WtVoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a function to compute the entropy of the frequency of the labels\n",
        "def entropy(labels):\n",
        "  total_labels = len(labels)\n",
        "  unique_labels = list(set(labels)) #find the different unique labels present in labels\n",
        "  num_labels=np.array([])\n",
        "  for label in unique_labels:\n",
        "    num_labels = np.append(num_labels,len(labels[labels==label])) #find the number of instances of each label\n",
        "  num_labels_pmf=num_labels/total_labels #normalize the number of instances of each label\n",
        "  log_num_labels_pmf = np.log2(num_labels_pmf) #compute the log2() of the normalized num labels\n",
        "  entropy_var= sum(-num_labels_pmf*log_num_labels_pmf) #compute the entropy as: sum_i -pi*log(pi)\n",
        "  return [entropy_var,num_labels,total_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUIMmKozx25q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a function to compute the entropy when the labels are split into two partitions.\n",
        "#The resulting entropy is the weighted average of the two partitions, each weighted by its fractions of samples.\n",
        "def entropy_split(labels_split):\n",
        "  total_labels = 0\n",
        "  num_labels=np.array([])\n",
        "  entropy_labels=np.array([])\n",
        "  for item in labels_split: #iterate over the partitions\n",
        "    total_labels+=len(item) #compute the total number of samples\n",
        "    num_labels=np.append(num_labels,len(item)) #compute the number of labels in each partition\n",
        "    entropy_labels=np.append(entropy_labels,entropy(item)[0]) #compute the entropy for each partition\n",
        "  num_labels = num_labels/total_labels #make it a pmf\n",
        "  entropy_split_var = sum(num_labels*entropy_labels) #compute the weighted entropy\n",
        "  return entropy_split_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9D1uh0Osvta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a function that optimally splits a set of samples depending on the given feature such that the resulting entropy is minimized\n",
        "def split_samples_feature(samples,labels,feature):\n",
        "  num_points = 100 #The search for the optimal threshold is restricted to 100 equally spaced points between the min and max\n",
        "  min_feature=min(samples[:,feature]) #the minimum value observed for the feature\n",
        "  max_feature=max(samples[:,feature]) #the maximum value observed for the feature\n",
        "  thresholds = np.linspace(min_feature,max_feature,num_points) #obtain the candidate thresholds (equally spaced values between min and max)\n",
        "  curr_entropy = entropy(labels)[0] #initialize entropy to that of the combined labels (entropy of any split will be less than this value)\n",
        "  curr_threshold = thresholds[0] #initialize the threshold to the min value\n",
        "  for threshold in thresholds: #iterate over the thresholds\n",
        "    labels_1=labels[samples[:,feature]<=threshold] # obtain the first partition based on the candidate threshold\n",
        "    labels_2=labels[samples[:,feature]>threshold]  # obtain the second partition based on the candidate threshold\n",
        "    labels_split = [labels_1,labels_2] # collect the two partitions\n",
        "    new_entropy = entropy_split(labels_split) #compute the entropy of the new split\n",
        "    if(new_entropy < curr_entropy):#compare the entropy for the new split with best entropy so far. If the new entropy is smaller than the best so far, update the values\n",
        "      curr_entropy = new_entropy # update the best entropy\n",
        "      curr_threshold = threshold # update the best threshold\n",
        "    labels_1=labels[samples[:,feature]<=curr_threshold] # labels partition 1 of the best split\n",
        "    labels_2=labels[samples[:,feature]>curr_threshold] # labels partition 2 of the best split\n",
        "    samples_1=samples[samples[:,feature]<=curr_threshold,:] # sample partition 1 of the best split\n",
        "    samples_2=samples[samples[:,feature]>curr_threshold,:] # sample partition 2 of the best split\n",
        "  return [curr_threshold,curr_entropy,labels_1,labels_2,samples_1,samples_2] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE9x4luE13A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function the splits a given set of samples based on best feature that minimizes the entropy\n",
        "def split_samples(samples,labels,parent_node,max_depth,curr_depth):\n",
        "  curr_threshold=float('inf') #initialize best threshold to an arbitrary value\n",
        "  [curr_entropy,num_labels,total_labels] = entropy(labels) #obtain the entropy, number of labels in each class and the total number of labels/samples\n",
        "  parent_node.entropy_before_split=curr_entropy # store the entropy of the current set of samples before splitting in the node class. This is just for information afterwards when analysing the tree.\n",
        "  parent_node.num_labels=num_labels # store the number of labels in the node class\n",
        "  parent_node.total_labels=total_labels # store the total number of labels in the node class\n",
        "  curr_feature = 0\n",
        "  found_split = False #initialize the boolean to false. This will be set to True when a split that minimizes entropy is found\n",
        "  for feature in range(samples.shape[1]): #iterate over features\n",
        "    [new_threshold,new_entropy,labels_1,labels_2,samples_1,samples_2] = split_samples_feature(samples,labels,feature) # find the best split for this feature\n",
        "    if(new_entropy < curr_entropy): #if the new feature is better\n",
        "      found_split=True \n",
        "      curr_feature = feature\n",
        "      curr_entropy=new_entropy\n",
        "      curr_threshold = new_threshold\n",
        "      curr_labels_1=labels_1\n",
        "      curr_labels_2=labels_2\n",
        "      curr_samples_1=samples_1\n",
        "      curr_samples_2=samples_2\n",
        "  parent_node.split=found_split\n",
        "  parent_node.depth=curr_depth\n",
        "  if found_split : #once the best feature is obtained, populate the node class with the relevant information\n",
        "    parent_node.feature=curr_feature # store the best feature to split at the current node\n",
        "    parent_node.entropy_after_split=curr_entropy #store the entropy after the split. This should be less than the entropy before split\n",
        "    parent_node.threshold=curr_threshold # store the threshold at which to split\n",
        "    if(curr_depth<max_depth): # if the depth of the current node is less than the max_depth, then continue the splitting process\n",
        "      node_left=Tree() #initialize a new node to be attached to the left of the current node.\n",
        "      node_right=Tree() #similarly, initialize a new node to be attached to the right of the current node\n",
        "      parent_node.left=node_left #link the parent node to the child nodes\n",
        "      parent_node.right=node_right\n",
        "      node_left.parent=parent_node #link the child nodes to the parent node\n",
        "      node_left.is_left=True # store whether the child node is a left node or a right node\n",
        "      node_right.parent=parent_node\n",
        "      node_right.is_left=False\n",
        "      split_samples(curr_samples_1,curr_labels_1,node_left,max_depth,curr_depth+1) #call a recursion on the same function with the new set of samples corresponding to the left partition\n",
        "      split_samples(curr_samples_2,curr_labels_2,node_right,max_depth,curr_depth+1) #similarly for the right partition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Cfcm_9dD2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to print the relevant information of the final decision tree\n",
        "def print_tree(root):\n",
        "  print(\"Node level = \", root.depth,\". Is left = \",root.is_left,\". Node Entropy before split = \",root.entropy_before_split,\". Node Entropy after split = \",root.entropy_after_split)\n",
        "  print(\"\\t Node feature = \", root.feature,\". Node threshold = \", root.threshold)\n",
        "  print(\"\\t Num labels = \", root.num_labels,\". Total number of labels = \", root.total_labels)\n",
        "  if(root.left): print_tree(root.left) # a recursion on the child nodes\n",
        "  if(root.right): print_tree(root.right)\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkkvdux_MOkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main code body\n",
        "from sklearn.datasets import load_wine  # Load in-built dataset on classification of wines\n",
        "data = load_wine()\n",
        "samples=data['data'] # obtain the samples\n",
        "labels=data['target'] # obtain the labels\n",
        "curr_depth=0 # the depth of the root node is initialized to 0\n",
        "max_depth=2  # specify the maximum depth to which the tree can grow\n",
        "root = Tree() #initialize the root node\n",
        "split_samples(samples,labels,root,max_depth,curr_depth) # Call the main function that computes the decision tree\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bU2Yz87qyIQ",
        "colab_type": "code",
        "outputId": "e18dbade-1f66-4f05-d521-ce960065e5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "print_tree(root)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Node level =  0 . Is left =  False . Node Entropy before split =  1.5668222768551812 . Node Entropy after split =  0.9260146995661807\n",
            "\t Node feature =  6 . Node threshold =  1.584848484848485\n",
            "\t Num labels =  [59. 71. 48.] . Total number of labels =  178\n",
            "Node level =  1 . Is left =  True . Node Entropy before split =  0.7918583525674836 . Node Entropy after split =  0.11178702106396361\n",
            "\t Node feature =  9 . Node threshold =  3.847474747474748\n",
            "\t Num labels =  [15. 48.] . Total number of labels =  63\n",
            "Node level =  2 . Is left =  True . Node Entropy before split =  0.0 . Node Entropy after split =  None\n",
            "\t Node feature =  None . Node threshold =  None\n",
            "\t Num labels =  [14.] . Total number of labels =  14\n",
            "Node level =  2 . Is left =  False . Node Entropy before split =  0.14372616993938178 . Node Entropy after split =  0.0\n",
            "\t Node feature =  2 . Node threshold =  2.02\n",
            "\t Num labels =  [ 1. 48.] . Total number of labels =  49\n",
            "Node level =  1 . Is left =  False . Node Entropy before split =  0.9995090461828582 . Node Entropy after split =  0.24829732413130304\n",
            "\t Node feature =  12 . Node threshold =  717.0101010101009\n",
            "\t Num labels =  [59. 56.] . Total number of labels =  115\n",
            "Node level =  2 . Is left =  True . Node Entropy before split =  0.13503620280212764 . Node Entropy after split =  0.06122853769502889\n",
            "\t Node feature =  0 . Node threshold =  13.116767676767676\n",
            "\t Num labels =  [ 1. 52.] . Total number of labels =  53\n",
            "Node level =  2 . Is left =  False . Node Entropy before split =  0.345117314944953 . Node Entropy after split =  0.0\n",
            "\t Node feature =  9 . Node threshold =  3.4272727272727277\n",
            "\t Num labels =  [58.  4.] . Total number of labels =  62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDT05SClZhYQ",
        "colab_type": "text"
      },
      "source": [
        "## Use scikit-learn's in-built implementation of decision trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmtcm9iuX05U",
        "colab_type": "code",
        "outputId": "9c21bce8-94f7-4e47-e4b5-07403a73ce46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#We will verify our implementation of the decision tree using the in-built implementation of decision tree in scikit learn\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn import tree\n",
        "data = load_wine()\n",
        "clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=2)\n",
        "clf = clf.fit(data.data, data.target)\n",
        "tree.plot_tree(clf.fit(data.data, data.target)) "
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 181.2, 'X[6] <= 1.575\\nentropy = 1.567\\nsamples = 178\\nvalue = [59, 71, 48]'),\n",
              " Text(83.7, 108.72, 'X[9] <= 3.825\\nentropy = 0.771\\nsamples = 62\\nvalue = [0, 14, 48]'),\n",
              " Text(41.85, 36.23999999999998, 'entropy = 0.0\\nsamples = 13\\nvalue = [0, 13, 0]'),\n",
              " Text(125.55000000000001, 36.23999999999998, 'entropy = 0.144\\nsamples = 49\\nvalue = [0, 1, 48]'),\n",
              " Text(251.10000000000002, 108.72, 'X[12] <= 724.5\\nentropy = 1.0\\nsamples = 116\\nvalue = [59, 57, 0]'),\n",
              " Text(209.25, 36.23999999999998, 'entropy = 0.133\\nsamples = 54\\nvalue = [1, 53, 0]'),\n",
              " Text(292.95, 36.23999999999998, 'entropy = 0.345\\nsamples = 62\\nvalue = [58, 4, 0]')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3dsRWzrVlfE",
        "colab_type": "text"
      },
      "source": [
        "# Exercises\n",
        "* Make changes so that the decision tree is based on minimizing the gini index (replace entropy with gini index).\n",
        "* Verify your implementation using the scikit-learn implementation of the decision tree, with the criterion set to gini."
      ]
    }
  ]
}